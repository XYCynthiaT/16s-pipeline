The flag 'directory' used in rule all is only valid for outputs, not inputs.
The flag 'directory' used in rule all is only valid for outputs, not inputs.
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	fastqcScore
	2

[Mon Dec 23 17:25:56 2019]
rule fastqcScore:
    input: s4FastQC/r1_fastqc.zip, s4FastQC/r2_fastqc.zip
    output: s4FastQC/r1_fastqc, s4FastQC/r2_fastqc
    jobid: 1

[Mon Dec 23 17:25:57 2019]
Error in rule fastqcScore:
    jobid: 1
    output: s4FastQC/r1_fastqc, s4FastQC/r2_fastqc

RuleException:
CalledProcessError in line 147 of /home/xinyut/workflows/16s-pipeline/Snakefile:
Command 'set -x; /home/xinyut/miniconda3/envs/16s-pipeline/bin/python3.7 /home/xinyut/workflows/16s-pipeline/.snakemake/scripts/tmpvrperbzm.fastqcscore.py' returned non-zero exit status 1.
  File "/home/xinyut/workflows/16s-pipeline/Snakefile", line 147, in __rule_fastqcScore
  File "/home/xinyut/miniconda3/envs/16s-pipeline/lib/python3.7/concurrent/futures/thread.py", line 57, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/xinyut/workflows/16s-pipeline/.snakemake/log/2019-12-23T172555.426896.snakemake.log
