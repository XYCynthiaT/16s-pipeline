Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	6	CutAdapt
	1	Demultiplex_rev
	1	all
	6	concatenate
	1	demultiplex_fwd
	1	fastQC
	16

[Thu Dec 19 16:45:56 2019]
rule demultiplex_fwd:
    input: s0RawData/barcode, s0RawData/demo_r1.fq.gz, s0RawData/demo_r2.fq.gz
    output: s1Demultiplex/first.1.r1.fastq, s1Demultiplex/first.2.r1.fastq, s1Demultiplex/first.3.r1.fastq, s1Demultiplex/first.4.r1.fastq, s1Demultiplex/first.5.r1.fastq, s1Demultiplex/first.6.r1.fastq, s1Demultiplex/first.1.r2.fastq, s1Demultiplex/first.2.r2.fastq, s1Demultiplex/first.3.r2.fastq, s1Demultiplex/first.4.r2.fastq, s1Demultiplex/first.5.r2.fastq, s1Demultiplex/first.6.r2.fastq, s1Demultiplex/first.unmatched.r1.fastq, s1Demultiplex/first.unmatched.r2.fastq, s1Demultiplex/first.Sample.r1.fastq, s1Demultiplex/first.Sample.r2.fastq
    jobid: 14

[Thu Dec 19 16:45:56 2019]
Finished job 14.
1 of 16 steps (6%) done

[Thu Dec 19 16:45:56 2019]
rule Demultiplex_rev:
    input: s0RawData/barcode, s1Demultiplex/first.unmatched.r2.fastq, s1Demultiplex/first.unmatched.r1.fastq
    output: s1Demultiplex/second.1.r1.fastq, s1Demultiplex/second.2.r1.fastq, s1Demultiplex/second.3.r1.fastq, s1Demultiplex/second.4.r1.fastq, s1Demultiplex/second.5.r1.fastq, s1Demultiplex/second.6.r1.fastq, s1Demultiplex/second.1.r2.fastq, s1Demultiplex/second.2.r2.fastq, s1Demultiplex/second.3.r2.fastq, s1Demultiplex/second.4.r2.fastq, s1Demultiplex/second.5.r2.fastq, s1Demultiplex/second.6.r2.fastq, s1Demultiplex/second.unmatched.r1.fastq, s1Demultiplex/second.unmatched.r2.fastq, s1Demultiplex/second.Sample.r1.fastq, s1Demultiplex/second.Sample.r2.fastq
    jobid: 15

[Thu Dec 19 16:45:57 2019]
Finished job 15.
2 of 16 steps (12%) done

[Thu Dec 19 16:45:57 2019]
rule CutAdapt:
    input: s0RawData/barcode, s1Demultiplex/first.5.r1.fastq, s1Demultiplex/first.5.r2.fastq, s1Demultiplex/second.5.r2.fastq, s1Demultiplex/second.5.r1.fastq
    output: s2CutAdapt/first.5.r1.fastq, s2CutAdapt/first.5.r2.fastq, s2CutAdapt/second.5.r2.fastq, s2CutAdapt/second.5.r1.fastq
    jobid: 12
    wildcards: sample=5

[Thu Dec 19 16:45:57 2019]
Finished job 12.
3 of 16 steps (19%) done

[Thu Dec 19 16:45:57 2019]
rule CutAdapt:
    input: s0RawData/barcode, s1Demultiplex/first.6.r1.fastq, s1Demultiplex/first.6.r2.fastq, s1Demultiplex/second.6.r2.fastq, s1Demultiplex/second.6.r1.fastq
    output: s2CutAdapt/first.6.r1.fastq, s2CutAdapt/first.6.r2.fastq, s2CutAdapt/second.6.r2.fastq, s2CutAdapt/second.6.r1.fastq
    jobid: 13
    wildcards: sample=6

[Thu Dec 19 16:45:58 2019]
Finished job 13.
4 of 16 steps (25%) done

[Thu Dec 19 16:45:58 2019]
rule CutAdapt:
    input: s0RawData/barcode, s1Demultiplex/first.1.r1.fastq, s1Demultiplex/first.1.r2.fastq, s1Demultiplex/second.1.r2.fastq, s1Demultiplex/second.1.r1.fastq
    output: s2CutAdapt/first.1.r1.fastq, s2CutAdapt/first.1.r2.fastq, s2CutAdapt/second.1.r2.fastq, s2CutAdapt/second.1.r1.fastq
    jobid: 8
    wildcards: sample=1

[Thu Dec 19 16:45:58 2019]
Finished job 8.
5 of 16 steps (31%) done

[Thu Dec 19 16:45:58 2019]
rule CutAdapt:
    input: s0RawData/barcode, s1Demultiplex/first.2.r1.fastq, s1Demultiplex/first.2.r2.fastq, s1Demultiplex/second.2.r2.fastq, s1Demultiplex/second.2.r1.fastq
    output: s2CutAdapt/first.2.r1.fastq, s2CutAdapt/first.2.r2.fastq, s2CutAdapt/second.2.r2.fastq, s2CutAdapt/second.2.r1.fastq
    jobid: 9
    wildcards: sample=2

[Thu Dec 19 16:45:59 2019]
Finished job 9.
6 of 16 steps (38%) done

[Thu Dec 19 16:45:59 2019]
rule CutAdapt:
    input: s0RawData/barcode, s1Demultiplex/first.3.r1.fastq, s1Demultiplex/first.3.r2.fastq, s1Demultiplex/second.3.r2.fastq, s1Demultiplex/second.3.r1.fastq
    output: s2CutAdapt/first.3.r1.fastq, s2CutAdapt/first.3.r2.fastq, s2CutAdapt/second.3.r2.fastq, s2CutAdapt/second.3.r1.fastq
    jobid: 10
    wildcards: sample=3

[Thu Dec 19 16:45:59 2019]
Finished job 10.
7 of 16 steps (44%) done

[Thu Dec 19 16:45:59 2019]
rule CutAdapt:
    input: s0RawData/barcode, s1Demultiplex/first.4.r1.fastq, s1Demultiplex/first.4.r2.fastq, s1Demultiplex/second.4.r2.fastq, s1Demultiplex/second.4.r1.fastq
    output: s2CutAdapt/first.4.r1.fastq, s2CutAdapt/first.4.r2.fastq, s2CutAdapt/second.4.r2.fastq, s2CutAdapt/second.4.r1.fastq
    jobid: 11
    wildcards: sample=4

[Thu Dec 19 16:46:00 2019]
Finished job 11.
8 of 16 steps (50%) done

[Thu Dec 19 16:46:00 2019]
rule concatenate:
    input: s2CutAdapt/first.1.r1.fastq, s2CutAdapt/second.1.r1.fastq, s2CutAdapt/first.1.r2.fastq, s2CutAdapt/second.1.r2.fastq
    output: s3Combine/1.r1.fastq, s3Combine/1.r2.fastq
    jobid: 2
    wildcards: sample=1

[Thu Dec 19 16:46:00 2019]
Finished job 2.
9 of 16 steps (56%) done

[Thu Dec 19 16:46:00 2019]
rule concatenate:
    input: s2CutAdapt/first.5.r1.fastq, s2CutAdapt/second.5.r1.fastq, s2CutAdapt/first.5.r2.fastq, s2CutAdapt/second.5.r2.fastq
    output: s3Combine/5.r1.fastq, s3Combine/5.r2.fastq
    jobid: 6
    wildcards: sample=5

[Thu Dec 19 16:46:00 2019]
Finished job 6.
10 of 16 steps (62%) done

[Thu Dec 19 16:46:00 2019]
rule concatenate:
    input: s2CutAdapt/first.3.r1.fastq, s2CutAdapt/second.3.r1.fastq, s2CutAdapt/first.3.r2.fastq, s2CutAdapt/second.3.r2.fastq
    output: s3Combine/3.r1.fastq, s3Combine/3.r2.fastq
    jobid: 4
    wildcards: sample=3

[Thu Dec 19 16:46:00 2019]
Finished job 4.
11 of 16 steps (69%) done

[Thu Dec 19 16:46:00 2019]
rule concatenate:
    input: s2CutAdapt/first.6.r1.fastq, s2CutAdapt/second.6.r1.fastq, s2CutAdapt/first.6.r2.fastq, s2CutAdapt/second.6.r2.fastq
    output: s3Combine/6.r1.fastq, s3Combine/6.r2.fastq
    jobid: 7
    wildcards: sample=6

[Thu Dec 19 16:46:00 2019]
Finished job 7.
12 of 16 steps (75%) done

[Thu Dec 19 16:46:00 2019]
rule concatenate:
    input: s2CutAdapt/first.4.r1.fastq, s2CutAdapt/second.4.r1.fastq, s2CutAdapt/first.4.r2.fastq, s2CutAdapt/second.4.r2.fastq
    output: s3Combine/4.r1.fastq, s3Combine/4.r2.fastq
    jobid: 5
    wildcards: sample=4

[Thu Dec 19 16:46:00 2019]
Finished job 5.
13 of 16 steps (81%) done

[Thu Dec 19 16:46:00 2019]
rule concatenate:
    input: s2CutAdapt/first.2.r1.fastq, s2CutAdapt/second.2.r1.fastq, s2CutAdapt/first.2.r2.fastq, s2CutAdapt/second.2.r2.fastq
    output: s3Combine/2.r1.fastq, s3Combine/2.r2.fastq
    jobid: 3
    wildcards: sample=2

[Thu Dec 19 16:46:00 2019]
Finished job 3.
14 of 16 steps (88%) done

[Thu Dec 19 16:46:00 2019]
rule fastQC:
    input: s3Combine/1.r1.fastq, s3Combine/2.r1.fastq, s3Combine/3.r1.fastq, s3Combine/4.r1.fastq, s3Combine/5.r1.fastq, s3Combine/6.r1.fastq, s3Combine/1.r2.fastq, s3Combine/2.r2.fastq, s3Combine/3.r2.fastq, s3Combine/4.r2.fastq, s3Combine/5.r2.fastq, s3Combine/6.r2.fastq
    output: s4FastQC/r1.fastq.gz, s4FastQC/r2.fastq.gz, s4FastQC/r1_fastqc.html, s4FastQC/r2_fastqc.html, s4FastQC/r1_fastqc.zip, s4FastQC/r2_fastqc.zip
    jobid: 1

[Thu Dec 19 16:46:00 2019]
Error in rule fastQC:
    jobid: 1
    output: s4FastQC/r1.fastq.gz, s4FastQC/r2.fastq.gz, s4FastQC/r1_fastqc.html, s4FastQC/r2_fastqc.html, s4FastQC/r1_fastqc.zip, s4FastQC/r2_fastqc.zip
    shell:
        
		cat s3Combine/1.r1.fastq s3Combine/2.r1.fastq s3Combine/3.r1.fastq s3Combine/4.r1.fastq s3Combine/5.r1.fastq s3Combine/6.r1.fastq|gzip -c > s4FastQC/r1.fastq.gz
		cat s3Combine/1.r2.fastq s3Combine/2.r2.fastq s3Combine/3.r2.fastq s3Combine/4.r2.fastq s3Combine/5.r2.fastq s3Combine/6.r2.fastq|gzip -c > s4FastQC/r2.fastq.gz
		fastqc -o s4FastQC s4FastQC/r1.fastq.gz s4FastQC/r2.fastq.gz
		
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job fastQC since they might be corrupted:
s4FastQC/r1.fastq.gz, s4FastQC/r2.fastq.gz
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/xinyut/workflows/16s-pipeline/.snakemake/log/2019-12-19T164556.102541.snakemake.log
