Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	DownloadRefDB
	1	all
	2

[Sun Dec 29 22:08:55 2019]
rule DownloadRefDB:
    input: urls
    output: ../../silva/SILVA_SSU_r132_March2018.RData
    jobid: 1

[Sun Dec 29 22:09:00 2019]
Finished job 1.
1 of 2 steps (50%) done

[Sun Dec 29 22:09:00 2019]
localrule all:
    input: ../../silva/SILVA_SSU_r132_March2018.RData
    jobid: 0

[Sun Dec 29 22:09:00 2019]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /home/xinyut/workflows/16s-pipeline/.snakemake/log/2019-12-29T220855.022016.snakemake.log
