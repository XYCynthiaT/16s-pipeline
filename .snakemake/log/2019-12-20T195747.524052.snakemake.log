Building DAG of jobs...
Using shell: /bin/bash
Provided cluster nodes: 20
Job counts:
	count	jobs
	1	DADA2
	1	all
	2

[Fri Dec 20 19:57:48 2019]
rule DADA2:
    input: s3Combine
    output: s5DADA2/DADA2_seqtab_nochim.rda, s5DADA2/img/ploterrF.png, s5DADA2/img/ploterrR.png
    jobid: 1

Submitted job 1 with external jobid 'Submitted batch job 16402402'.
[Fri Dec 20 19:58:18 2019]
Finished job 1.
1 of 2 steps (50%) done

[Fri Dec 20 19:58:18 2019]
localrule all:
    input: s5DADA2/DADA2_seqtab_nochim.rda, s5DADA2/img/ploterrF.png, s5DADA2/img/ploterrR.png
    jobid: 0

[Fri Dec 20 19:58:18 2019]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /home/xinyut/workflows/16s-pipeline/.snakemake/log/2019-12-20T195747.524052.snakemake.log
